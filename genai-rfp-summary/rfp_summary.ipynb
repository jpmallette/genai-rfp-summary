{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produce HTML with condensed prompt with all fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import pandas as pd # type: ignore\n",
    "from pandas import DataFrame # type: ignore\n",
    "from openai import OpenAI # type: ignore\n",
    "from rouge_score import rouge_scorer # type: ignore\n",
    "from openpyxl import Workbook # type: ignore\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows # type: ignore\n",
    "from openpyxl.styles import Alignment # type: ignore\n",
    "from openpyxl.utils import get_column_letter # type: ignore\n",
    "\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "ASSISTANT_ID = \"asst_ybGhVb3VbLVinE8r5NXXxKT5\" \n",
    "\n",
    "def clear_all_dataframes():\n",
    "    for name in list(globals()):\n",
    "        if isinstance(globals()[name], pd.DataFrame):\n",
    "            del globals()[name]\n",
    "clear_all_dataframes() # type: ignore\n",
    "\n",
    "def read_prompt_csv() -> DataFrame:\n",
    "    df_prompt = pd.read_csv('Data/Input-Output/df_scored_in.csv')\n",
    "    return df_prompt\n",
    "df_prompt = read_prompt_csv() # type: ignore\n",
    "\n",
    "def subset_df_prompt(df_prompt: DataFrame) -> DataFrame:\n",
    "    df_prompt_subset = df_prompt[['field','prompt_description']]\n",
    "    return df_prompt_subset\n",
    "df_prompt_subset = subset_df_prompt(df_prompt)\n",
    "\n",
    "def convert_df_prompt_to_prompt_str(df_prompt: DataFrame) -> str:\n",
    "    prompt_json_dict = {row['field']: row['prompt_description'] \n",
    "                        for index, row in df_prompt.iterrows()}\n",
    "    prompt = json.dumps(prompt_json_dict, indent=4)\n",
    "    return prompt\n",
    "prompt = convert_df_prompt_to_prompt_str(df_prompt_subset) # type: ignore \n",
    "\n",
    "def write_str_to_txt_file(str_object, file_path):\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(str_object)\n",
    "    return None\n",
    "write_str_to_txt_file(prompt,\"Data/Prompt/input_prompt.txt\") # for debug -- it's a log\n",
    "\n",
    "def run_assistant_code(prompt: str) -> DataFrame:\n",
    "    thread = client.beta.threads.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": (f\"Extract the values for each column and return a json format. \\n\"\n",
    "                           f\"return only the json format without additional words or context: {prompt}\")\n",
    "            },\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    run = client.beta.threads.runs.create(thread_id=thread.id, assistant_id=ASSISTANT_ID)\n",
    "\n",
    "    while run.status != \"completed\":\n",
    "        run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
    "        time.sleep(1)\n",
    "\n",
    "    message_response = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "    messages = message_response.data\n",
    "    return messages\n",
    "messages = run_assistant_code(prompt) # type: ignore -- also couple of error their.\n",
    "\n",
    "def parse_assistant_output_into_dict(messages):\n",
    "    def extract_json(text):\n",
    "        # Regular expression pattern to find JSON starting with `{` and ending with `}`\n",
    "        pattern = r'\\{.*\\}'\n",
    "        match = re.search(pattern, text, re.DOTALL)\n",
    "        if match:\n",
    "            return match.group(0)  # Return the matched JSON string\n",
    "        return None  # Return None if no JSON is found\n",
    "\n",
    "    latest_message = messages[0]\n",
    "    json_list = [block.text.value for block in latest_message.content]\n",
    "    cleaned_json_strings = [extract_json(text) for text in json_list if extract_json(text) is not None]\n",
    "    dictionaries = [json.loads(jstring) for jstring in cleaned_json_strings] \n",
    "    return dictionaries\n",
    "dictionaries = parse_assistant_output_into_dict(messages)\n",
    "\n",
    "def parse_assistant_output_dict_into_df(dictionaries):\n",
    "    df_chatgpt_values = pd.DataFrame(dictionaries)\n",
    "    df_chatgpt_values_transposed = df_chatgpt_values.transpose()\n",
    "    df_chatgpt_values_transposed.reset_index(inplace=True)\n",
    "    df_chatgpt_values_transposed.columns = ['field', 'chatgpt_value']\n",
    "    return df_chatgpt_values_transposed\n",
    "df_chatgpt = parse_assistant_output_dict_into_df(dictionaries)\n",
    "\n",
    "def replace_values_no_information_string_to_nan(df_chatgpt: DataFrame):\n",
    "    values_to_replace = re.compile(r'\\b(no|not specified|not provided|not explicit|in the document)\\b', re.IGNORECASE)\n",
    "    return df_chatgpt['chatgpt_value'].replace(values_to_replace,pd.NA)\n",
    "df_chatgpt['chatgpt_value'] = replace_values_no_information_string_to_nan(df_chatgpt)\n",
    "\n",
    "def retrieve_category(df_chatgpt: DataFrame) -> DataFrame:\n",
    "    df_field_category = pd.read_csv('Data/Supplemental/field_category.csv')\n",
    "    df_chatgpt_category = pd.merge(df_chatgpt, df_field_category, on='field')\n",
    "    return df_chatgpt_category\n",
    "df_chatgpt_category = retrieve_category(df_chatgpt)\n",
    "\n",
    "def generate_html(df_chatgpt_category: DataFrame):\n",
    "    html_output = \"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html lang=\"en\">\n",
    "    <head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <title>Opportunity Information</title>\n",
    "    <style>\n",
    "        body { font-family: Arial, sans-serif; background: #fff; color: #333; }\n",
    "        .category { margin-bottom: 20px; }\n",
    "        .header { background: #007BFF; padding: 10px; cursor: pointer; color: #fff; }\n",
    "        .content { border: 1px solid #ccc; border-top: none; padding: 10px; display: flex; flex-wrap: wrap; }\n",
    "        .column { flex: 50%; }\n",
    "        .field { box-sizing: border-box; padding: 5px; }\n",
    "        .field-name { font-weight: bold; }\n",
    "        img.logo { height: 50px; margin-bottom: 20px; display: block; }\n",
    "    </style>\n",
    "    <script>\n",
    "        document.addEventListener(\"DOMContentreaded\", function() {\n",
    "            var headers = document.querySelectorAll('.header');\n",
    "            headers.forEach(function(header) {\n",
    "                header.addEventListener('click', function() {\n",
    "                    var content = this.nextElementSibling;\n",
    "                    content.style.display = content.style.display === 'flex' ? 'none' : 'flex';\n",
    "                });\n",
    "            });\n",
    "        });\n",
    "    </script>\n",
    "    </head>\n",
    "    <body>\n",
    "\n",
    "    <img src=\"buscom_logo.jpeg\" class=\"logo\" alt=\"Bus.com Logo\">\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the order of categories\n",
    "    category_order = [\n",
    "        \"Opportunity Information\",\n",
    "        \"High Level Summary\",\n",
    "        \"Dates and Deadlines\",\n",
    "        \"Opportunity Team & Contacts\",\n",
    "        \"Estimates\",\n",
    "        \"RFP Summary\",\n",
    "        \"Deal Specifics\",\n",
    "        \"Additional Information\",\n",
    "        \"Lost Opportunity Analysis\"\n",
    "    ]\n",
    "\n",
    "    # Define specific field orderings for complex categories\n",
    "    dates_fields_left = [\"Posted Date\", \"Deadline for Questions\", \"Prebid Attendance\", \"Pre-Bid Conference\",\n",
    "                        \"Proposal Deadline Date\", \"Interview Information\", \"Last Addendum Date\"]\n",
    "    dates_fields_right = [\"Event Start Date\", \"Event End Date\", \"Contract Duration (Months)\",\n",
    "                        \"Contract Extension Term\", \"Options to Renew\"]\n",
    "    contacts_fields = [\"Contact: Title\", \"Contact: Email\", \"Contact: Phone\"]\n",
    "    estimates_left = [\"Estimated Contract Value\", \"Estimated Supplier Amount\"]\n",
    "    estimates_right = [\"Estimated Cost\", \"Custom Payment Terms\"]\n",
    "    rfp_summary_left = [\"Region Area Name\", \"Region Area Kind\", \"RFP Name\", \"RFP Service Type\", \"Submission Type\", \"Award Type\"]\n",
    "    rfp_summary_right = [\"Subcontracting Allowed\", \"Supplier Partner\", \"Incumbent Supplier\", \"Pricing Type\", \"Proposal Writer\"]\n",
    "    deal_specifics_left = [\"Number of Buses\", \"Facility Provided by Agency\", \"Maintenance Provided by Agency\", \"Parking Provided by Agency\", \"Living Wage Requirements\", \"Disadvantaged Business Requirements\", \"Fleet Requirement\", \"Fuel Provided By\", \"Vehicle Fuel Type\", \"Technology Needed\", \"Technology Partner\", \"Bidder References Required\", \"Liquidated Damages\"]\n",
    "    deal_specifics_right = [\"Number of Awarded Vendors\", \"Facility Notes\", \"Maintenance Notes\", \"Parking Notes\", \"Living Wage Comments\", \"Disadvantaged Business Comments\", \"Fleet Requirement Comments\", \"Fuel Notes\", \"Vehicle Provider\", \"Technology Description\", \"Bidder References Description\", \"Liquidated Damage Information\"]\n",
    "\n",
    "    # Loop through the predefined list of categories\n",
    "    for category in category_order:\n",
    "        if category in df_chatgpt_category['category'].values:\n",
    "            filtered_df = df_chatgpt_category[df_chatgpt_category['category'] == category]\n",
    "            html_output += f'<div class=\"category\">\\n    <div class=\"header\">{category}</div>\\n    <div class=\"content\" style=\"display: flex;\">'\n",
    "\n",
    "            if category == \"Dates and Deadlines\":\n",
    "                # Specific handling for Dates and Deadlines with left and right columns\n",
    "                html_output += '<div class=\"column\">\\n'\n",
    "                for field in dates_fields_left:\n",
    "                    if field in filtered_df['field'].values:\n",
    "                        value = filtered_df.loc[filtered_df['field'] == field, 'chatgpt_value'].iloc[0]\n",
    "                        html_output += f'        <div class=\"field\"><span class=\"field-name\">{field}:</span> {value}</div>\\n'\n",
    "                html_output += '</div>\\n<div class=\"column\">\\n'\n",
    "                for field in dates_fields_right:\n",
    "                    if field in filtered_df['field'].values:\n",
    "                        value = filtered_df.loc[filtered_df['field'] == field, 'chatgpt_value'].iloc[0]\n",
    "                        html_output += f'        <div class=\"field\"><span class=\"field-name\">{field}:</span> {value}</div>\\n'\n",
    "                html_output += '</div>\\n'\n",
    "\n",
    "            elif category == \"Opportunity Team & Contacts\":\n",
    "                # Vertical display for contact fields\n",
    "                for field in contacts_fields:\n",
    "                    if field in filtered_df['field'].values:\n",
    "                        value = filtered_df.loc[filtered_df['field'] == field, 'chatgpt_value'].iloc[0]\n",
    "                        html_output += f'        <div class=\"field\" style=\"flex: 100%;\"><span class=\"field-name\">{field}:</span> {value}</div>\\n'\n",
    "\n",
    "            elif category == \"Estimates\":\n",
    "                # Split fields into two columns for Estimates\n",
    "                html_output += '<div class=\"column\">\\n'\n",
    "                for field in estimates_left:\n",
    "                    if field in filtered_df['field'].values:\n",
    "                        value = filtered_df.loc[filtered_df['field'] == field, 'chatgpt_value'].iloc[0]\n",
    "                        html_output += f'        <div class=\"field\"><span class=\"field-name\">{field}:</span> {value}</div>\\n'\n",
    "                html_output += '</div>\\n<div class=\"column\">\\n'\n",
    "                for field in estimates_right:\n",
    "                    if field in filtered_df['field'].values:\n",
    "                        value = filtered_df.loc[filtered_df['field'] == field, 'chatgpt_value'].iloc[0]\n",
    "                        html_output += f'        <div class=\"field\"><span class=\"field-name\">{field}:</span> {value}</div>\\n'\n",
    "                html_output += '</div>\\n'\n",
    "\n",
    "            elif category == \"RFP Summary\" or category == \"Deal Specifics\":\n",
    "                # Handle RFP Summary and Deal Specifics with custom field orders\n",
    "                html_output += '<div class=\"column\">\\n'\n",
    "                fields_left = rfp_summary_left if category == \"RFP Summary\" else deal_specifics_left\n",
    "                for field in fields_left:\n",
    "                    if field in filtered_df['field'].values:\n",
    "                        value = filtered_df.loc[filtered_df['field'] == field, 'chatgpt_value'].iloc[0]\n",
    "                        html_output += f'        <div class=\"field\"><span class=\"field-name\">{field}:</span> {value}</div>\\n'\n",
    "                html_output += '</div>\\n<div class=\"column\">\\n'\n",
    "                fields_right = rfp_summary_right if category == \"RFP Summary\" else deal_specifics_right\n",
    "                for field in fields_right:\n",
    "                    if field in filtered_df['field'].values:\n",
    "                        value = filtered_df.loc[filtered_df['field'] == field, 'chatgpt_value'].iloc[0]\n",
    "                        html_output += f'        <div class=\"field\"><span class=\"field-name\">{field}:</span> {value}</div>\\n'\n",
    "                html_output += '</div>\\n'\n",
    "\n",
    "            elif category == \"Additional Information\":\n",
    "                # Vertical display of all fields for Additional Information\n",
    "                for index, row in filtered_df.iterrows():\n",
    "                    html_output += f'        <div class=\"field\" style=\"flex: 100%;\"><span class=\"field-name\">{row[\"field\"]}:</span> {row[\"chatgpt_value\"]}</div>\\n'\n",
    "\n",
    "            else:\n",
    "                # Normal field handling for other categories\n",
    "                for index, row in filtered_df.iterrows():\n",
    "                    html_output += f'        <div class=\"field\"><span class=\"field-name\">{row[\"field\"]}:</span> {row[\"chatgpt_value\"]}</div>\\n'\n",
    "\n",
    "            html_output += '    </div>\\n</div>\\n'\n",
    "\n",
    "    html_output += \"\"\"\n",
    "        </body>\n",
    "        </html>\n",
    "    \"\"\"\n",
    "    return html_output\n",
    "html_content = generate_html(df_chatgpt_category)\n",
    "\n",
    "def save_html(html_content):\n",
    "    html_file_path = \"HTML-CSS/rfp_summary.html\"\n",
    "    with open(html_file_path, 'w') as file:\n",
    "        file.write(html_content)\n",
    "    return None\n",
    "save_html(html_content)\n",
    "\n",
    "def retrieve_prompt_description(df_chatgpt_category, df_prompt):\n",
    "    df_chatgpt_category_prompt_description = pd.merge(df_chatgpt_category, \n",
    "                             df_prompt[['field', 'prompt_description']]\n",
    "                             , on='field'\n",
    "                             , how='left')\n",
    "    return df_chatgpt_category_prompt_description    \n",
    "df_chatgpt_category_prompt_description = retrieve_prompt_description(df_chatgpt_category, df_prompt)\n",
    "\n",
    "def retrieve_score_type(df_chatgpt_category_prompt_description):\n",
    "    df_score_type = pd.read_csv('Data/Supplemental/field_score_type.csv')\n",
    "    df_chatgpt_category_prompt_description_score = pd.merge(df_chatgpt_category_prompt_description, \n",
    "                             df_score_type,\n",
    "                              on='field',\n",
    "                              how='left')\n",
    "    return df_chatgpt_category_prompt_description_score    \n",
    "df_chatgpt_category_prompt_description_score = retrieve_score_type(df_chatgpt_category_prompt_description)\n",
    "\n",
    "def read_sf_csv() -> DataFrame:\n",
    "    try:\n",
    "        df_sf = pd.read_csv('Data/Test/test_city_of_turlock.csv')\n",
    "        return df_sf\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Failed to read data: {e}\")\n",
    "df_sf = read_sf_csv() # type: ignore\n",
    "\n",
    "def merge_df_test_with_df_chatgpt(df_sf: DataFrame,df_chatgpt_category_prompt_description_score: DataFrame):\n",
    "    df_sf_chatgpt = pd.merge(df_sf, \n",
    "                             df_chatgpt_category_prompt_description_score[['field', 'chatgpt_value','prompt_description','field_score_type']]\n",
    "                             , on='field'\n",
    "                             , how='right')\n",
    "    return df_sf_chatgpt\n",
    "df_sf_chatgpt = merge_df_test_with_df_chatgpt(df_sf,df_chatgpt_category_prompt_description_score)\n",
    "\n",
    "def reorder_df_sf_chatgpt_column(df_sf_chatgpt: DataFrame):\n",
    "    new_order = ['field', 'prompt_description','field_score_type','chatgpt_value','sf_value']\n",
    "    return df_sf_chatgpt[new_order]\n",
    "df_sf_chatgpt = reorder_df_sf_chatgpt_column(df_sf_chatgpt) \n",
    "\n",
    "def standardize_missing_values(df):\n",
    "    for column in df.columns:\n",
    "        df[column] = df[column].map(lambda x: pd.NA if pd.isna(x) else x)\n",
    "    return df\n",
    "df_sf_chatgpt = standardize_missing_values(df_sf_chatgpt) \n",
    "\n",
    "def score_df(df_sf_chatgpt: DataFrame) -> DataFrame:\n",
    "    field_score_types = ['binary', 'human']\n",
    "    processed_dfs = []\n",
    "    \n",
    "    for field_score_type in field_score_types:\n",
    "        processed_df = process_scores(df_sf_chatgpt, field_score_type)\n",
    "        processed_dfs.append(processed_df)\n",
    "    \n",
    "    df_sf_chatgpt_score_type_prepared_score = pd.concat(processed_dfs, axis=0).drop_duplicates()\n",
    "    df_sf_chatgpt_score_type_prepared_score['score'] = df_sf_chatgpt_score_type_prepared_score['score'].round(2)\n",
    "\n",
    "    return df_sf_chatgpt_score_type_prepared_score\n",
    "def process_scores(df, score_type):\n",
    "    \"\"\"Process scores based on field_score_type, filtering data to relevant rows.\"\"\"\n",
    "    df_filtered = df[df['field_score_type'] == score_type].copy()\n",
    "    if score_type == 'binary':\n",
    "        return calculate_binary_score(df_filtered, 'sf_value', 'chatgpt_value')\n",
    "    elif score_type == 'human':\n",
    "        return calculate_rouge_l(df_filtered, 'sf_value', 'chatgpt_value')\n",
    "    else:\n",
    "        raise ValueError(\"Invalid score_type provided. Choose 'binary' or 'human'.\")\n",
    "def calculate_binary_score(df, col1, col2):\n",
    "    \"\"\"Calculates binary score comparing two column values where pd.NA values are considered equal.\"\"\"\n",
    "    def custom_na_comparison(x, y):\n",
    "        if pd.isna(x) and pd.isna(y):\n",
    "            return 1  \n",
    "        elif pd.isna(x) or pd.isna(y):\n",
    "            return 0 \n",
    "        elif x == y:\n",
    "            return 1 \n",
    "        else:\n",
    "            return 0 \n",
    "    # Apply custom comparison across the columns\n",
    "    df['score'] = [custom_na_comparison(x, y) for x, y in zip(df[col1], df[col2])]\n",
    "    return df\n",
    "def calculate_rouge_l(df, col1, col2):\n",
    "    \"\"\"Applies ROUGE-L score calculation to DataFrame.\"\"\"\n",
    "    scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "    df['score'] = df.apply(lambda row: scorer.score(str(row[col1])\n",
    "                                                    , str(row[col2]))['rougeL'].fmeasure\n",
    "                                                    , axis=1)\n",
    "    return df\n",
    "df_sf_chatgpt_score = score_df(df_sf_chatgpt)   \t\t\t\n",
    "\n",
    "df_sf_chatgpt_score.to_csv('Data/Input-Output/df_scored_out.csv')\n",
    "\n",
    "def write_to_excel(df: DataFrame):\n",
    "    wb = Workbook()\n",
    "    ws = wb.active\n",
    "    df = df.where(pd.notna(df), None)\n",
    "\n",
    "    for r_idx, row in enumerate(dataframe_to_rows(df, index=False, header=True), 1):\n",
    "        for c_idx, value in enumerate(row, 1):\n",
    "            cell = ws.cell(row=r_idx, column=c_idx, value=value)\n",
    "            # Set both center alignment and wrap text\n",
    "            cell.alignment = Alignment(horizontal='center', vertical='center', wrap_text=False)\n",
    "\n",
    "    chatgpt_column_letter = get_column_letter(df.columns.get_loc('chatgpt_value') + 1)\n",
    "    prompt_description_column_letter = get_column_letter(df.columns.get_loc('prompt_description') + 1)\n",
    "    sf_value_column_letter = get_column_letter(df.columns.get_loc('sf_value') + 1)\n",
    "\n",
    "    ws.column_dimensions[chatgpt_column_letter].width = 100\n",
    "    ws.column_dimensions[prompt_description_column_letter].width = 40\n",
    "\n",
    "    for row in ws.iter_rows(min_row=1, max_row=ws.max_row):\n",
    "        ws.row_dimensions[row[0].row].height = 20\n",
    "\n",
    "    wb.save('Data/Input-Output/df_scored_out.xlsx')\n",
    "write_to_excel(df_sf_chatgpt_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MVP: Functions to score and extract many fields, many RFPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed run 1 with gpt-3.5-turbo at temperature 0.7 for event_start_date_prompt_v2 and asst_wQcnhTkLgrFfGRrHXP6QC2Ya\n",
      "Completed run 1 with gpt-4o-mini at temperature 0.7 for event_start_date_prompt_v2 and asst_wQcnhTkLgrFfGRrHXP6QC2Ya\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>opportunity_name</th>\n",
       "      <th>field</th>\n",
       "      <th>config</th>\n",
       "      <th>sf_value</th>\n",
       "      <th>chatgpt_value</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>City of Calabasas, CA Fixed 2024</td>\n",
       "      <td>Event Start Date</td>\n",
       "      <td>gpt-3.5-turbo_0.7_v2</td>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>City of Calabasas, CA Fixed 2024</td>\n",
       "      <td>Event Start Date</td>\n",
       "      <td>gpt-4o-mini_0.7_v2</td>\n",
       "      <td>2024-07-01</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   opportunity_name             field                config  \\\n",
       "0  City of Calabasas, CA Fixed 2024  Event Start Date  gpt-3.5-turbo_0.7_v2   \n",
       "1  City of Calabasas, CA Fixed 2024  Event Start Date    gpt-4o-mini_0.7_v2   \n",
       "\n",
       "     sf_value chatgpt_value  score  \n",
       "0  2024-07-01    2022-09-01    0.0  \n",
       "1  2024-07-01                  0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from itertools import product\n",
    "from pathlib import Path\n",
    "import time\n",
    "import re\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from openai import OpenAI\n",
    "from rouge_score import rouge_scorer\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "N_RUN = 1\n",
    "# One assistant ID per RFP # asst_3ZZ33RlX4eAApKD2EskbYIsj asst_wQcnhTkLgrFfGRrHXP6QC2Ya\n",
    "ASSISTANT_IDS = [\"asst_wQcnhTkLgrFfGRrHXP6QC2Ya\"] \n",
    "\n",
    "def clear_all_dataframes():\n",
    "    for name in list(globals()):\n",
    "        if isinstance(globals()[name], pd.DataFrame):\n",
    "            del globals()[name]\n",
    "clear_all_dataframes()\n",
    "\n",
    "def read_txt_file(filename):\n",
    "    file_path = Path(f\"Data/Prompt/{filename}\")\n",
    "    content = file_path.read_text()\n",
    "    return content, filename\n",
    "\n",
    "prompt_files = ['event_start_date_prompt_v2.txt']\n",
    "prompts = [read_txt_file(fname) for fname in prompt_files]\n",
    "param_grid = {\n",
    "    'temperature': [0.7],\n",
    "    'model': ['gpt-3.5-turbo','gpt-4o-mini'],\n",
    "    'prompt_details': prompts\n",
    "}\n",
    "\n",
    "def create_grid(param_grid):\n",
    "    for params in product(*param_grid.values()):\n",
    "        yield dict(zip(param_grid.keys(), params))\n",
    "\n",
    "def update_assistant(assistant_id, model, temperature):\n",
    "    return client.beta.assistants.update(\n",
    "        assistant_id=assistant_id,\n",
    "        model=model,\n",
    "        temperature=temperature\n",
    "    )\n",
    "\n",
    "def run_assistant_code(assistant_id: str, prompt: str) -> DataFrame:\n",
    "    thread = client.beta.threads.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                 \"content\": (f\"Extract the values for each column and return a json format. \\n\"\n",
    "                           f\"return only the json format without additional words or context: {prompt}\")\n",
    "            },\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    run = client.beta.threads.runs.create(thread_id=thread.id, assistant_id=assistant_id)\n",
    "\n",
    "    while run.status != \"completed\":\n",
    "        run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
    "        time.sleep(1)\n",
    "\n",
    "    message_response = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "    messages = message_response.data\n",
    "    return messages\n",
    "def parse_assistant_output_into_dict(messages):\n",
    "    def extract_json(text):\n",
    "        # Regular expression pattern to find JSON starting with `{` and ending with `}`\n",
    "        pattern = r'\\{.*\\}'\n",
    "        match = re.search(pattern, text, re.DOTALL)\n",
    "        if match:\n",
    "            return match.group(0)  # Return the matched JSON string\n",
    "        return None  # Return None if no JSON is found\n",
    "\n",
    "    latest_message = messages[0]\n",
    "    json_list = [block.text.value for block in latest_message.content]\n",
    "    cleaned_json_strings = [extract_json(text) for text in json_list if extract_json(text) is not None]\n",
    "    dictionaries = [json.loads(jstring) for jstring in cleaned_json_strings] \n",
    "    return dictionaries\n",
    "def parse_assistant_output_dict_into_df(dictionaries):\n",
    "    df_chatgpt_values = pd.DataFrame(dictionaries)\n",
    "    df_chatgpt_values_transposed = df_chatgpt_values.transpose()\n",
    "    df_chatgpt_values_transposed.reset_index(inplace=True)\n",
    "    df_chatgpt_values_transposed.columns = ['field', 'chatgpt_value']\n",
    "    return df_chatgpt_values_transposed\n",
    "\n",
    "all_dfs = []\n",
    "for assistant_id in ASSISTANT_IDS:\n",
    "    for params in create_grid(param_grid):\n",
    "        assistant = update_assistant(\n",
    "            assistant_id,\n",
    "            params['model'],\n",
    "            params['temperature']\n",
    "        )\n",
    "\n",
    "        for i in range(N_RUN):\n",
    "            prompt_content, prompt_filename = params['prompt_details']\n",
    "            messages = run_assistant_code(assistant_id, prompt_content)\n",
    "            dictionaries = parse_assistant_output_into_dict(messages)\n",
    "            df_chatgpt_one_run = parse_assistant_output_dict_into_df(dictionaries)\n",
    "            df_chatgpt_one_run = df_chatgpt_one_run.assign(\n",
    "                run_number=i + 1,\n",
    "                model_used=params['model'],\n",
    "                temperature=params['temperature'],\n",
    "                assistant_id=assistant_id,\n",
    "                prompt_version=prompt_filename.split('_')[-1].split('.')[0]\n",
    "            )\n",
    "            print(f'Completed run {i + 1} with {params[\"model\"]} at temperature {params[\"temperature\"]} for {prompt_filename[:-4]} and {assistant_id}')\n",
    "            all_dfs.append(df_chatgpt_one_run)\n",
    "\n",
    "combined_df = pd.concat(all_dfs, ignore_index=True)\n",
    "combined_df['config'] = combined_df.apply(lambda x: f\"{x['model_used']}_{x['temperature']}_{x['prompt_version']}\", axis=1)\n",
    "\n",
    "df_assistant = pd.read_csv('Data/Assistant/assistant_data.csv')\n",
    "combined_df_with_assistant = pd.merge(df_assistant, \n",
    "                             combined_df[['field', 'chatgpt_value', 'run_number','config','assistant_id']],\n",
    "                             on='assistant_id', \n",
    "                             how='right')\n",
    "combined_df_with_assistant.rename(columns={'assistant_name': 'opportunity_name'}, inplace=True)\n",
    "\n",
    "df_sf = pd.read_csv('Data/Test/test_both_city_of_turlock_calabases.csv')\n",
    "df_simulation_sf_chatgpt = pd.merge(df_sf, \n",
    "                             combined_df_with_assistant[['field', 'chatgpt_value'\n",
    "                                                         , 'run_number', 'config','opportunity_name']],\n",
    "                             on=['field','opportunity_name'], \n",
    "                             how='right')\n",
    "\n",
    "def retrieve_score_type(df_chatgpt_category_prompt_description):\n",
    "    df_score_type = pd.read_csv('Data/Supplemental/field_score_type.csv')\n",
    "    df_chatgpt_category_prompt_description_score = pd.merge(df_chatgpt_category_prompt_description, \n",
    "                             df_score_type,\n",
    "                              on='field',\n",
    "                              how='left')\n",
    "    return df_chatgpt_category_prompt_description_score    \n",
    "df_simulation_sf_chatgpt_score_type = retrieve_score_type(df_simulation_sf_chatgpt)\n",
    "\n",
    "def score_df(df_sf_chatgpt: DataFrame) -> DataFrame:\n",
    "    field_score_types = ['binary', 'human']\n",
    "    processed_dfs = []\n",
    "    \n",
    "    for field_score_type in field_score_types:\n",
    "        processed_df = process_scores(df_sf_chatgpt, field_score_type)\n",
    "        processed_dfs.append(processed_df)\n",
    "    \n",
    "    df_sf_chatgpt_score_type_prepared_score = pd.concat(processed_dfs, axis=0).drop_duplicates()\n",
    "    df_sf_chatgpt_score_type_prepared_score['score'] = df_sf_chatgpt_score_type_prepared_score['score'].round(2)\n",
    "\n",
    "    return df_sf_chatgpt_score_type_prepared_score\n",
    "def process_scores(df, score_type):\n",
    "    \"\"\"Process scores based on field_score_type, filtering data to relevant rows.\"\"\"\n",
    "    df_filtered = df[df['field_score_type'] == score_type].copy()\n",
    "    if score_type == 'binary':\n",
    "        return calculate_binary_score(df_filtered, 'sf_value', 'chatgpt_value')\n",
    "    elif score_type == 'human':\n",
    "        return calculate_rouge_l(df_filtered, 'sf_value', 'chatgpt_value')\n",
    "    else:\n",
    "        raise ValueError(\"Invalid score_type provided. Choose 'binary' or 'human'.\")\n",
    "def calculate_binary_score(df, col1, col2):\n",
    "    \"\"\"Calculates binary score comparing two column values where pd.NA values are considered equal.\"\"\"\n",
    "    def custom_na_comparison(x, y):\n",
    "        if pd.isna(x) and pd.isna(y):\n",
    "            return 1  \n",
    "        elif pd.isna(x) or pd.isna(y):\n",
    "            return 0 \n",
    "        elif x == y:\n",
    "            return 1 \n",
    "        else:\n",
    "            return 0 \n",
    "    # Apply custom comparison across the columns\n",
    "    df['score'] = [custom_na_comparison(x, y) for x, y in zip(df[col1], df[col2])]\n",
    "    return df\n",
    "def calculate_rouge_l(df, col1, col2):\n",
    "    \"\"\"Applies ROUGE-L score calculation to DataFrame.\"\"\"\n",
    "    scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "    df['score'] = df.apply(lambda row: scorer.score(str(row[col1])\n",
    "                                                    , str(row[col2]))['rougeL'].fmeasure\n",
    "                                                    , axis=1)\n",
    "    return df\n",
    "\n",
    "df_simulation_runs_sf_chatgpt_scored = score_df(df_simulation_sf_chatgpt_score_type)\n",
    "\n",
    "#df_simulation_runs_sf_chatgpt_scored.to_csv(\"Data/Consistency/simulation_end_date_data_only_gpt_4_turbo.csv\")\n",
    "df_reorder = df_simulation_runs_sf_chatgpt_scored[['opportunity_name', 'field'\n",
    "                                                   , 'config', 'sf_value', 'chatgpt_value'\n",
    "                                                   , 'score']]\n",
    "df_reorder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
